# common-services

![Version: 1.0.9](https://img.shields.io/badge/Version-1.0.9-informational?style=flat-square) ![Type: application](https://img.shields.io/badge/Type-application-informational?style=flat-square) ![AppVersion: 1.3](https://img.shields.io/badge/AppVersion-1.3-informational?style=flat-square)

A Helm chart for deploying RadiantOne Common Services on Kubernetes

## Maintainers

| Name | Email | Url |
| ---- | ------ | --- |
| pgodey | <pgodey@radiantlogic.com> | <https://www.radiantlogic.com> |

## Requirements

Kubernetes: `>=1.24.0-0`

| Repository | Name | Version |
|------------|------|---------|
| https://argoproj.github.io/argo-helm | argo-cd | 5.6.0 |
| https://charts.bitnami.com/bitnami | postgresql | 12.1.3 |
| https://charts.bitnami.com/bitnami | zookeeper | 11.0.0 |
| https://cloudnative-pg.github.io/charts | cloudnative-pg | 0.21.4 |
| https://fluent.github.io/helm-charts | fluent-bit | 0.39.0 |
| https://grafana.github.io/helm-charts | grafana | 6.40.0 |
| https://haproxytech.github.io/helm-charts | haproxy | 1.17.3 |
| https://helm.elastic.co | elasticsearch | 7.17.3 |
| https://helm.elastic.co | kibana | 7.17.3 |
| https://helm.runix.net | pgadmin4 | 1.13.8 |
| https://opensearch-project.github.io/helm-charts | opensearch | 2.16.1 |
| https://opensearch-project.github.io/helm-charts | opensearch-dashboards | 2.14.0 |
| https://prometheus-community.github.io/helm-charts | prometheus | 15.13.0 |
| https://vmware-tanzu.github.io/helm-charts | velero | 7.2.1 |

## Values

| Key | Type | Default | Description |
|-----|------|---------|-------------|
| argo-cd | object | `{"applicationSet":{"enabled":false},"configs":{"params":{"server.insecure":true,"server.rootpath":"/argocd"}},"controller":{"nodeSelector":{}},"crds":{"keep":false},"dex":{"enabled":false},"enabled":true,"fullnameOverride":"argocd","notifications":{"enabled":false},"redis":{"nodeSelector":{}},"repoServer":{"nodeSelector":{}},"server":{"nodeSelector":{},"service":{"type":"NodePort"}}}` | -------------------  This section enables and configures Argo CD, a GitOps continuous delivery tool for Kubernetes.  Key Features: - Automated application deployment and synchronization from Git repositories - Declarative configuration using Kubernetes manifests - Visual UI for managing applications and observing their state - Optional integration with Dex for authentication and authorization - Customizable server settings (root path, security) - Node selector configuration for different Argo CD components  Note: Review and adjust settings for production environments. |
| backupManager | object | `{"affinity":{},"enabled":false,"image":{"pullPolicy":"Always","repository":"radiantone/backup-manager","tag":"dev"},"imagePullSecrets":[],"log":{"format":"text","level":"info"},"nodeSelector":{},"podAnnotations":{},"podSecurityContext":{},"replicas":1,"resources":{"limits":{"cpu":"250m","memory":"512Mi"},"requests":{"cpu":"250m","memory":"256Mi"}},"securityContext":{},"service":{"containerPort":8080,"port":80},"swagger":{"enabled":false,"host":"localhost","port":8080},"tolerations":[],"webhook":{"backup":{"timeout":"1h","url":""},"enabled":false,"restore":{"timeout":"1h","url":""},"syncPeriod":"1m"}}` | --------------------------------------------------------------- |
| cloudnative-pg | object | `{"affinity":{},"config":{"create":true,"data":{"INHERITED_ANNOTATIONS":"meta.helm.sh/*, helm.sh/*","INHERITED_LABELS":"app.kubernetes.io/*, radiantlogic.io/*"},"name":"cnpg-controller-manager-config"},"enabled":false,"fullnameOverride":"cnpg","nodeSelector":{},"tolerations":[]}` | --------------------------------------------------------------- |
| curator | object | `{"client":{"certificate":"","client_cert":"","client_key":"","hosts":["elasticsearch-master"],"master_only":false,"password":"","port":9200,"ssl_no_validate":true,"timeout":300,"use_ssl":false,"username":""},"cronjob":{"annotations":{},"concurrencyPolicy":"","failedJobsHistoryLimit":"","jobRestartPolicy":"Never","labels":{},"schedule":"0 0 * * *","startingDeadlineSeconds":"","successfulJobsHistoryLimit":""},"dryrun":false,"enabled":true,"hooks":{"install":false,"upgrade":false},"logging":{"blacklist":["elasticsearch","urllib3"],"logfile":"","logformat":"default","loglevel":"INFO"},"logs":[{"name":"vds_server.log"},{"name":"vds_server_access.log"},{"name":"adap_access.log"},{"name":"adap.log"},{"name":"web.log"},{"name":"web_access.log"},{"name":"event.log"},{"name":"periodiccache.log"},{"name":"admin_rest_api_access.log"},{"name":"sync_engine.log"},{"name":"alerts.log"},{"name":"approvals_audit.log"},{"name":"scim.log"},{"name":"audit.log"},{"name":"internal-container.log"}],"nodeSelector":{},"pod":{"annotations":{}},"priorityClassName":"","psp":{"create":false},"rbac":{"enabled":false},"resources":{},"securityContext":{"runAsUser":16},"serviceAccount":{"annotations":{},"create":false}}` | ------------------ This section controls the behavior of Elasticsearch Curator, a tool for managing Elasticsearch indices. Curator can perform actions like deleting, closing, or creating indices based on configured filters. |
| curator.client | object | `{"certificate":"","client_cert":"","client_key":"","hosts":["elasticsearch-master"],"master_only":false,"password":"","port":9200,"ssl_no_validate":true,"timeout":300,"use_ssl":false,"username":""}` | --------------------------- Specify the connection details for your Elasticsearch cluster. |
| curator.cronjob.schedule | string | `"0 0 * * *"` | ------------------------ Configure the Kubernetes CronJob that will trigger Curator actions. Cron schedule (e.g., every day) |
| curator.logging.loglevel | string | `"INFO"` | ---------------------------- Customize how Curator logs its activities. Set the desired log level (DEBUG, INFO, WARNING, ERROR, CRITICAL) |
| elasticsearch | object | `{"clusterHealthCheckParams":"wait_for_status=yellow&timeout=60s","enabled":true,"nodeSelector":{},"replicas":1,"volumeClaimTemplate":{"resources":{"requests":{"storage":"30Gi"}}}}` | ---------------------------------  This section enables deployment of an Elasticsearch cluster and Kibana for log management and visualization.  Key Features: - Single-node Elasticsearch cluster (customizable replica count) - Persistent storage for Elasticsearch data - Kibana instance with customizable base path and telemetry settings - Configurable node selectors for pod placement  Important Considerations: - Adjust storage size (`volumeClaimTemplate.resources.requests.storage`) to match your needs. - Modify `clusterHealthCheckParams` based on your cluster's expected health status and timeout. |
| fluent-bit | object | `{"aggregators":[],"enabled":false,"existingConfigMap":"fluent-bit-config","flush":1,"fullnameOverride":"fluent-bit","logLevel":"info","logs":[{"aggregators":["elasticsearch"],"enable":true,"name":"eoc-backend","path":"/var/log/containers/eoc-backend-*.log","refresh_interval":10},{"aggregators":["elasticsearch"],"enable":true,"name":"eoc-orchestrator","path":"/var/log/containers/eoc-orchestrator-*.log","refresh_interval":10},{"aggregators":["elasticsearch"],"enable":true,"name":"sdc","path":"/var/log/containers/sdc-*.log","refresh_interval":10},{"aggregators":["elasticsearch"],"enable":true,"name":"client-router","path":"/var/log/containers/client-*.log","refresh_interval":10},{"aggregators":["elasticsearch"],"enable":true,"name":"tunnel","path":"/var/log/containers/r1tunnel*.log","refresh_interval":10}],"metricsPort":2020,"nodeSelector":{},"outputSearchHost":"elasticsearch-master","outputSearchType":"es","prometheusRule":{"enabled":false},"service":{"type":"ClusterIP"},"serviceMonitor":{"enabled":false}}` | ---------------------- This section controls the deployment and configuration of Fluent Bit, a lightweight and high-performance log processor and forwarder. Enable/Disable Fluent Bit: Set `enabled` to `true` to deploy Fluent Bit. Node Selection (Optional): Use `nodeSelector` to schedule Fluent Bit pods onto specific nodes. Log Sources (Required): Define a list of log sources that Fluent Bit should collect.    - For each source, specify:        - `name`: A descriptive name for the log source.        - `enable`: Whether to collect logs from this source (`true` or `false`).        - `path`: The path to the log files (use wildcards like `*`).        - `refresh_interval`: How often Fluent Bit checks for new log data (in seconds). Output Destination (Required): Configure where Fluent Bit should send the collected logs.    - `outputSearchHost`: Hostname or IP of your Elasticsearch (or OpenSearch) cluster.    - `outputSearchType`:  Choose either "es" for Elasticsearch or "opensearch". Fluent Bit Configuration (Optional): Fine-tune Fluent Bit's behavior.    - `fullnameOverride`: Customize the name of Fluent Bit resources (e.g., DaemonSet).    - `flush`: How often Fluent Bit sends logs to the output destination (in seconds).    - `logLevel`:  Logging verbosity ("info", "debug", etc.).    - `metricsPort`: Port for exposing Fluent Bit metrics. Service (Optional): Expose Fluent Bit's metrics or other ports via a Kubernetes Service. Monitoring (Optional):    - `prometheusRule`: Enable to create a PrometheusRule for Fluent Bit metrics.    - `serviceMonitor`: Enable to create a ServiceMonitor to scrape Fluent Bit metrics with Prometheus Operator. Existing ConfigMap (Optional): If you have a pre-existing ConfigMap with custom Fluent Bit configuration, specify its name here. |
| grafana | object | `{"dashboardProviders":{"dashboardproviders.yaml":{"apiVersion":1,"providers":[{"allowUiUpdates":true,"disableDeletion":false,"editable":true,"folder":"","name":"fid","options":{"path":"/var/lib/grafana/dashboards/fid"},"orgId":1,"type":"file","updateIntervalSeconds":10},{"allowUiUpdates":true,"disableDeletion":false,"editable":true,"folder":"","name":"zookeeper","options":{"path":"/var/lib/grafana/dashboards/zookeeper"},"orgId":1,"type":"file","updateIntervalSeconds":10},{"allowUiUpdates":true,"disableDeletion":false,"editable":true,"folder":"","name":"elasticsearch","options":{"path":"/var/lib/grafana/dashboards/elasticsearch"},"orgId":1,"type":"file","updateIntervalSeconds":10},{"allowUiUpdates":true,"disableDeletion":false,"editable":true,"folder":"","name":"service-status","options":{"path":"/var/lib/grafana/dashboards/service-status"},"orgId":1,"type":"file","updateIntervalSeconds":10},{"allowUiUpdates":true,"disableDeletion":false,"editable":true,"folder":"","name":"ia-service-status","options":{"path":"/var/lib/grafana/dashboards/ia-service-status"},"orgId":1,"type":"file","updateIntervalSeconds":10},{"allowUiUpdates":true,"disableDeletion":false,"editable":true,"folder":"","name":"ida","options":{"path":"/var/lib/grafana/dashboards/ida"},"orgId":1,"type":"file","updateIntervalSeconds":10},{"allowUiUpdates":true,"disableDeletion":false,"editable":true,"folder":"","name":"ia-controller-beam","options":{"path":"/var/lib/grafana/dashboards/ia-controller-beam"},"orgId":1,"type":"file","updateIntervalSeconds":10},{"allowUiUpdates":true,"disableDeletion":false,"editable":true,"folder":"","name":"ia-controller-ecto","options":{"path":"/var/lib/grafana/dashboards/ia-controller-ecto"},"orgId":1,"type":"file","updateIntervalSeconds":10},{"allowUiUpdates":true,"disableDeletion":false,"editable":true,"folder":"","name":"ia-controller-oban","options":{"path":"/var/lib/grafana/dashboards/ia-controller-oban"},"orgId":1,"type":"file","updateIntervalSeconds":10},{"allowUiUpdates":true,"disableDeletion":false,"editable":true,"folder":"","name":"ia-controller-phoenix","options":{"path":"/var/lib/grafana/dashboards/ia-controller-phoenix"},"orgId":1,"type":"file","updateIntervalSeconds":10},{"allowUiUpdates":true,"disableDeletion":false,"editable":true,"folder":"","name":"ia-data-ingestion","options":{"path":"/var/lib/grafana/dashboards/ia-data-ingestion"},"orgId":1,"type":"file","updateIntervalSeconds":10},{"allowUiUpdates":true,"disableDeletion":false,"editable":true,"folder":"","name":"ia-extractor-webapp","options":{"path":"/var/lib/grafana/dashboards/ia-extractor-webapp"},"orgId":1,"type":"file","updateIntervalSeconds":10},{"allowUiUpdates":true,"disableDeletion":false,"editable":true,"folder":"","name":"ia-governance-portal","options":{"path":"/var/lib/grafana/dashboards/ia-governance-portal"},"orgId":1,"type":"file","updateIntervalSeconds":10}]}},"dashboardsConfigMaps":{"elasticsearch":"audit-logs-elastic-dashboard","fid":"fid-dashboard","ia-controller-beam":"ia-controller-beam-dashboard","ia-controller-ecto":"ia-controller-ecto-dasboard","ia-controller-oban":"ia-controller-oban-dashboard","ia-controller-phoenix":"ia-controller-phoenix-dashboard","ia-data-ingestion":"ia-data-ingestion-dashboard","ia-extractor-webapp":"ia-extractor-webapp-dashboard","ia-governance-portal":"ia-governance-portal-dashboard","ia-service-status":"ia-service-status-dashboard","ida":"ia-dashboard","service-status":"service-status-dashboard","zookeeper":"zookeeper-dashboard"},"datasources":{"datasources.yaml":{"apiVersion":1,"datasources":[{"access":"proxy","isDefault":true,"name":"Prometheus","type":"prometheus","url":"http://prometheus-server"},{"access":"proxy","database":"vds_server_access.log*","isDefault":false,"jsonData":{"esVersion":"7.17.3","logLevelField":"fields.level","logMessageField":"message","maxConcurrentShardRequests":5,"timeField":"@timestamp"},"name":"Elasticsearch","password":"","readonly":true,"type":"elasticsearch","url":"http://elasticsearch-master:9200","user":""},{"access":"proxy","isDefault":false,"jsonData":{"esVersion":70,"interval":"Daily","timeField":"@timestamp"},"name":"OpenSearch","readonly":true,"type":"opensearch","url":"http://opensearch-cluster-master:9200"}]}},"enabled":true,"fullnameOverride":"grafana","grafana.ini":{"analytics":{"check_for_updates":false},"auth.anonymous":{"enabled":true,"org_role":"Viewer"},"live":{"allowed_origins":"*"},"log":{"mode":"console"},"log.console":{"format":"text","level":"info"},"panels":{"disable_sanitize_html":true},"security":{"allow_embedding":true},"server":{"root_url":"%(protocol)s://%(domain)s/eoc-backend/grafana","serve_from_sub_path":true},"smtp":{"enabled":true,"from_address":"saas@radiantlogic.com","host":"smtp-server:25"}},"nodeSelector":{},"persistence":{"enabled":true,"size":"8Gi"}}` | -------------------  This section deploys and configures a Grafana instance, including:  - Persistent storage for dashboards and data - Data sources for Prometheus, Elasticsearch, Alertmanager, and OpenSearch - Dashboard provisioning from files (with customizable update intervals) - Configurable settings in `grafana.ini` (e.g., root URL, authentication) - Ability to override the Grafana name (`fullnameOverride`) - Configurable node selection and persistent storage options - Email (SMTP) setup for notifications (if enabled)  Note: Ensure correct data source URLs and credentials. Place dashboard JSON files in the specified directories. |
| haproxy | object | `{"config":"defaults\n  timeout connect 10s\n  timeout client 30s\n  timeout server 30s\n  log global\n  mode http\n  option httplog\n  maxconn 3000\nfrontend http-in\n  bind *:80\n\n  stats enable\n  stats refresh 30s\n  stats show-node\n  stats uri /stats\n  monitor-uri /healthz\n\n  # Remove unnecessary headers\n  http-response del-header Server\n  http-response del-header X-Powered-By\n  http-response del-header X-AspNetMvc-Version\n  http-response del-header X-AspNet-Version\n  http-response del-header X-Drupal-Cache\n  http-response del-header X-Drupal-Dynamic-Cache\n  http-response del-header X-Generator\n  http-response del-header X-Runtime\n  http-response del-header X-Rack-Cache\n\n  # Add security headers\n  http-response set-header Strict-Transport-Security \"max-age=16000000; includeSubDomains; preload;\"\n  http-response set-header X-Frame-Options \"SAMEORIGIN\"\n  http-response set-header X-Content-Type-Options \"nosniff\"\n  http-response set-header Referrer-Policy no-referrer-when-downgrade\n  http-response set-header X-XSS-Protection 1;mode=block\n  http-response set-header Permissions-Policy interest-cohort=()\n\n\n  # routing\n  {{- if ((.Values.route).argocd | default false) }}\n  use_backend argocd_backend if { path /argocd } or { path_beg /argocd/ }\n  {{- end }}\n  {{- if ((.Values.route).grafana | default false) }}\n  use_backend grafana_backend if { path /grafana } or { path_beg /grafana/ }\n  {{- end }}\n  {{- if ((.Values.route).prometheus | default false) }}\n  use_backend prometheus_backend if { path /prometheus } or { path_beg /prometheus/ }\n  {{- end }}\n  {{- if ((.Values.route).pushgateway | default false) }}\n  use_backend pushgateway_backend if { path /pushgateway } or { path_beg /pushgateway/ }\n  {{- end }}\n  {{- if ((.Values.route).kibana | default false) }}\n  use_backend kibana_backend if { path /kibana } or { path_beg /kibana/ }\n  {{- end }}\n  {{- if ((.Values.route).elasticsearch | default false) }}\n  use_backend elasticsearch_backend if { path /elasticsearch } or { path_beg /elasticsearch/ }\n  {{- end }}\n  {{- if ((.Values.route).pgadmin4 | default false) }}\n  use_backend pgadmin4_backend if { path /pgadmin4 } or { path_beg /pgadmin4/ }\n  {{- end }}\n  {{- if ((.Values.route).slamd | default false) }}\n  use_backend slamd_backend if { path /slamd } or { path_beg /slamd/ }\n  {{- end }}\n  {{- if ((.Values.route).shellinabox | default false) }}\n  use_backend shellinabox_backend if { path /shellinabox } or { path_beg /shellinabox/ }\n  {{- end }}\n  {{- if ((.Values.route).eocui | default false) }}\n  use_backend eocui_backend if { path /eoc } or { path_beg /eoc/ }\n  {{- end }}\n  {{- if ((.Values.route).eocapi | default false) }}\n  use_backend eocapi_backend if { path /eoc-backend } or { path_beg /eoc-backend/ }\n  {{- end }}\n  {{- if ((.Values.route).sdccui | default false) }}\n  use_backend sdcapi_backend if { path /sdc } or { path_beg /sdc/ }\n  {{- end }}\n  {{- if ((.Values.route).opensearchdashboards | default false) }}\n  use_backend opensearchdashboards_backend if { path /opensearch-dashboards } or { path_beg /opensearch-dashboards/ }\n  {{- end }}\n  {{- if ((.Values.route).opensearch | default false) }}\n  use_backend opensearch_backend if { path /opensearch } or { path_beg /opensearch/ }\n  {{- end }}\n\n# backends\n{{- if ((.Values.route).argocd | default false) }}\nbackend argocd_backend\n  server argocd argocd-server:80 check\n{{- end }}\n{{- if ((.Values.route).grafana | default false) }}\nbackend grafana_backend\n  http-request set-path %[path,regsub(^/grafana/?,/)]\n  server grafana grafana:80 check\n{{- end }}\n{{- if ((.Values.route).prometheus | default false) }}\nbackend prometheus_backend\n  http-request set-path %[path,regsub(^/prometheus/?,/)]\n  server prometheus prometheus-server:80 check\n{{- end }}\n{{- if ((.Values.route).pushgateway | default false) }}\nbackend pushgateway_backend\n  http-request set-path %[path,regsub(^/pushgateway/?,/)]\n  server pushgateway prometheus-pushgateway:9091 check\n{{- end }}\n{{- if ((.Values.route).kibana | default false) }}\nbackend kibana_backend\n  http-request set-path %[path,regsub(^/kibana/?,/)]\n  server kibana kibana:5601 check\n{{- end }}\n{{- if ((.Values.route).elasticsearch | default false) }}\nbackend elasticsearch_backend\n  http-request set-path %[path,regsub(^/elasticsearch/?,/)]\n  server elasticsearch elasticsearch-master:9200 check\n{{- end }}\n{{- if ((.Values.route).pgadmin4 | default false) }}\nbackend pgadmin4_backend\n  server pgadmin4 pgadmin4:80 check\n{{- end }}\n{{- if ((.Values.route).slamd | default false) }}\nbackend slamd_backend\n  server slamd slamd:80 check\n{{- end }}\n{{- if ((.Values.route).shellinabox | default false) }}\nbackend shellinabox_backend\n  http-request set-path %[path,regsub(^/shellinabox/?,/)]\n  server shellinabox shellinabox:8080 check\n{{- end }}\n{{- if ((.Values.route).eocui | default false) }}\nbackend eocui_backend\n  server eocui eoc-ui-service:80 check\n{{- end }}\n{{- if ((.Values.route).eocapi | default false) }}\nbackend eocapi_backend\n  server eocapi eoc-backend-service:80 check\n{{- end }}\n{{- if ((.Values.route).sdccui | default false) }}\nbackend sdcapi_backend\n  server sdcapi sdc-agent:80 check\n{{- end }}\n{{- if ((.Values.route).opensearchdashboards | default false) }}\nbackend opensearchdashboards_backend\n  #http-request set-path %[path,regsub(^/opensearch-dashboards/?,/)]\n  server opensearchdashboards opensearch-dashboards:5601 check\n{{- end }}\n{{- if ((.Values.route).opensearch | default false) }}\nbackend opensearch_backend\n  http-request set-path %[path,regsub(^/opensearch/?,/)]\n  server opensearch opensearch-cluster-master:9200 check\n{{- end }}\n","enabled":true,"fullnameOverride":"haproxy","nodeSelector":{},"route":{"argocd":true,"elasticsearch":false,"eocapi":false,"eocui":false,"grafana":true,"kibana":true,"opensearch":false,"opensearchdashboards":false,"pgadmin4":false,"prometheus":false,"pushgateway":false,"sdcapi":false,"shellinabox":false,"slamd":false},"service":{"type":"NodePort"}}` | -------------------  This section configures HAProxy as an API gateway for internal services. It provides:   - Load balancing and routing for enabled services   - Basic security headers and connection timeouts   - Stats and health check endpoints   - Customization through the 'route' section (toggle services on/off)   - Fine-grained backend configuration using templating  Note: Ensure correct service names and ports in the backend definitions. |
| ingress | object | `{"annotations":{},"className":"alb","enabled":false,"hosts":[{"host":"chart-example.local","paths":["/"]}],"tls":[]}` | -------------------------------------- This section defines an Ingress resource to manage external access to services within your Kubernetes cluster. Key Features: - `className`: Specifies the Ingress controller to use ("alb" in this case, likely for AWS Application Load Balancer). - `hosts`: Lists the hostnames that the Ingress should respond to. - `paths`: Defines the URL paths that are routed to the corresponding services. - `tls`: Configures TLS certificates for secure HTTPS communication (optional). Note: Ensure the specified Ingress controller is installed and that the TLS configuration (if used) is valid. |
| kibana.enabled | bool | `true` |  |
| kibana.fullnameOverride | string | `"kibana"` |  |
| kibana.healthCheckPath | string | `"/eoc-backend/kibana"` |  |
| kibana.kibanaConfig."kibana.yml" | string | `"server.basePath: \"/eoc-backend/kibana\"\nserver.publicBaseUrl: http://kibana.{{ .Release.Namespace }}.svc.cluster.local:5601/eoc-backend/kibana\ntelemetry.optIn: false\nsecurity.showInsecureClusterWarning: false\nserver.rewriteBasePath: true\nserver.compression.enabled: true\nserver.requestId.allowFromAnyIp: true\n"` |  |
| kibana.nodeSelector | object | `{}` |  |
| nodeSelector | object | `{}` |  |
| opensearch | object | `{"clusterName":"opensearch-cluster","enabled":false,"extraEnvs":[{"name":"DISABLE_SECURITY_PLUGIN","value":"true"},{"name":"DISABLE_INSTALL_DEMO_CONFIG","value":"true"}],"fullnameOverride":"opensearch","masterService":"opensearch-cluster-master","nodeGroup":"master","nodeSelector":{},"persistence":{"size":"30Gi"},"podSecurityContext":{"fsGroup":1000,"runAsUser":1000},"rbac":{"create":false,"serviceAccountAnnotations":{},"serviceAccountName":""},"replicas":1,"service":{"annotations":{},"httpPortName":"http","nodePort":"","transportPortName":"transport","type":"ClusterIP"},"singleNode":true}` | ---------------------- This section controls the deployment of an OpenSearch cluster and its accompanying dashboard.  Key Settings:   - `enabled`: Set to `true` to deploy OpenSearch (and optionally OpenSearch Dashboards).   - `singleNode`: If `true`, a single-node cluster is created for development/testing.   - `replicas`: Number of data replicas for each primary shard (for high availability and scalability).   - `persistence.size`: Size of the persistent volume for storing OpenSearch data. |
| opensearch-dashboards.config."opensearch_dashboards.yml" | string | `"server:\n  basePath: \"/opensearch-dashboards\"\n  rewriteBasePath: true\n"` |  |
| opensearch-dashboards.enabled | bool | `false` |  |
| opensearch-dashboards.extraEnvs[0].name | string | `"DISABLE_SECURITY_DASHBOARDS_PLUGIN"` |  |
| opensearch-dashboards.extraEnvs[0].value | string | `"true"` |  |
| opensearch-dashboards.fullnameOverride | string | `"opensearch-dashboards"` |  |
| opensearch-dashboards.nodeSelector | object | `{}` |  |
| opensearch-dashboards.opensearchHosts | string | `"http://opensearch-cluster-master:9200"` |  |
| opensearch-dashboards.plugins.enabled | bool | `false` |  |
| opensearch-dashboards.plugins.installList | list | `[]` |  |
| opensearch-dashboards.replicaCount | int | `1` |  |
| opensearch-dashboards.service.annotations | object | `{}` |  |
| opensearch-dashboards.service.httpPortName | string | `"http"` |  |
| opensearch-dashboards.service.labels | object | `{}` |  |
| opensearch-dashboards.service.loadBalancerIP | string | `""` |  |
| opensearch-dashboards.service.loadBalancerSourceRanges | list | `[]` |  |
| opensearch-dashboards.service.nodePort | string | `""` |  |
| opensearch-dashboards.service.port | int | `5601` |  |
| opensearch-dashboards.service.type | string | `"ClusterIP"` |  |
| pgadmin4 | object | `{"enabled":true,"env":{"contextPath":"/pgadmin4"},"fullnameOverride":"pgadmin4","nodeSelector":{},"persistentVolume":{"enabled":false}}` | --------------------  This section enables deployment of pgAdmin4, a web-based administration tool for PostgreSQL databases.  Key Features: - Single-pod deployment of pgAdmin4 - Configurable context path for web access - Option to enable persistent storage for configuration data - Customizable node selection for pod placement  Note: Persistent storage is disabled by default. Enable it if you need to preserve pgAdmin4 configuration data across pod restarts. |
| postgresql | object | `{"databases":{"eoc":{"databaseName":"eocdb","password":"TSXojYsPF4AeZgTq","schema":"eoc","user":"eocadmin"},"sdc":{"databaseName":"agentsdb","password":"iJukleKLG9fNihIQ","schema":"agents","user":"agentsadmin"}},"enabled":true,"fullnameOverride":"postgresql","primary":{"initdb":{"scriptsConfigMap":"postgres-init-script"},"nodeSelector":{},"persistence":{"size":"10Gi"}}}` | -------------------------------  This section enables deployment and configuration of a PostgreSQL database cluster.  Key Features: - Single-node PostgreSQL deployment (can be expanded in more advanced scenarios) - Persistent storage for database data - Customizable initialization scripts via ConfigMap - Predefined databases for EOC and SDC applications - Option to configure backups to S3 (commented out by default)  Important Considerations: - Adjust storage size (`persistence.size`) to match your needs. - Securely manage database credentials (e.g., using Kubernetes Secrets). - If enabling backups, ensure proper S3 configuration and credentials. |
| prometheus | object | `{"alertmanager":{"enabled":false},"configmapReload":{"prometheus":{"enabled":false}},"enabled":true,"kubeStateMetrics":{"enabled":false},"nodeExporter":{"enabled":false},"pushgateway":{"extraArgs":{"web.enable-admin-api":true},"fullnameOverride":"prometheus-pushgateway","nodeSelector":{}},"server":{"extraFlags":["web.enable-lifecycle","web.route-prefix=/","web.external-url=http://prometheus-server/prometheus/","web.enable-admin-api"],"fullnameOverride":"prometheus-server","nodeSelector":{},"persistentVolume":{"size":"8Gi"},"statefulSet":{"enabled":true}}}` | --------------------------------------  This section enables deployment and configuration of Prometheus components:  - Prometheus Server: Core time-series database for metrics collection and querying. - Pushgateway (Optional):  Allows ephemeral and batch jobs to expose metrics. - Node Exporter, Kube State Metrics, Alertmanager (Optional): Additional components for node-level metrics, Kubernetes state metrics, and alerting respectively.  Key Features: - Customizable flags for Prometheus Server - Persistent storage options for Prometheus Server - Ability to enable/disable individual components - Configurable nodeSelectors for pod placement  Note: Ensure correct external URL for Prometheus Server and adjust storage as needed. |
| shellinabox | object | `{"affinity":{},"enabled":true,"image":{"pullPolicy":"IfNotPresent","repository":"sspreitzer/shellinabox","tag":"ubuntu"},"imagePullSecrets":[],"nodeSelector":{},"podAnnotations":{},"podSecurityContext":{},"replicaCount":1,"resources":{},"securityContext":{},"service":{"port":8080,"type":"ClusterIP"},"tolerations":[]}` | ----------------------  This section enables deployment of Shellinabox, a web-based SSH terminal emulator.  Key Features: - Single-pod deployment of Shellinabox - Customizable Docker image repository and tag - Configurable service type and port for access - Optional settings for pod and container security - Resource management options for CPU and memory - Node selection, tolerations, and affinity controls for pod scheduling  Note: Review and adjust security settings based on your environment's requirements. |
| slamd | object | `{"affinity":{},"autoscaling":{"enabled":false,"maxReplicas":100,"minReplicas":1,"targetCPUUtilizationPercentage":80},"client":{"affinity":{},"autoscaling":{"enabled":false,"maxReplicas":100,"minReplicas":1,"targetCPUUtilizationPercentage":80},"image":{"pullPolicy":"IfNotPresent","repository":"pgodey/slamd-client","tag":"latest"},"nodeSelector":{},"podAnnotations":{},"podSecurityContext":{},"replicaCount":0,"resources":{},"securityContext":{},"tolerations":[]},"enabled":true,"image":{"pullPolicy":"IfNotPresent","repository":"pgodey/slamd","tag":"latest"},"imagePullSecrets":[],"nodeSelector":{},"podAnnotations":{},"podSecurityContext":{},"replicaCount":1,"resources":{},"securityContext":{},"service":{"port":80,"type":"ClusterIP"},"tolerations":[]}` | ------------------  This section enables deployment of SLAMD, a tool for load testing and benchmarking LDAP directories.  Key Features: - Deploy SLAMD server and optionally client instances - Customize image versions and pull policies - Configure pod and container security settings - Define resource requests and limits for SLAMD components - Optionally enable autoscaling based on CPU utilization - Configure node selectors, tolerations, and affinity for pod placement  Note: Review and adjust settings according to your testing requirements. |
| smtp | object | `{"affinity":{},"enabled":true,"image":{"pullPolicy":"IfNotPresent","repository":"bytemark/smtp","tag":"latest"},"imagePullSecrets":[],"nodeSelector":{},"podAnnotations":{},"podSecurityContext":{},"relay":{"enabled":true,"host":"smtp.sendgrid.net","password":"","port":"587","username":""},"replicaCount":1,"resources":{},"securityContext":{},"service":{"port":8080,"type":"ClusterIP"},"tolerations":[]}` | ----------------------  This section enables deployment of an SMTP relay container to send emails from within the Kubernetes cluster.  Key Features: - Single-pod deployment of SMTP relay - Configurable SMTP relay host, port, and authentication credentials - Customizable Docker image repository and tag - Configurable service type and port for access - Optional settings for pod and container security - Resource management options for CPU and memory - Node selection, tolerations, and affinity controls for pod scheduling  Note: Ensure correct SMTP relay credentials and adjust security settings based on your environment's requirements. |
| velero | object | `{"backupStorage":{"bucket":"","prefix":null,"region":"","validationFrequency":"1h"},"cleanUpCRDs":true,"configuration":{"backupStorageLocation":"nil","defaultBackupTTL":"168h","garbageCollectionFrequency":"1h","volumeSnapshotLocation":"nil"},"credentials":{"useSecret":false},"enabled":false,"fullnameOverride":"velero","initContainers":[{"image":"velero/velero-plugin-for-aws:v1.10.1","imagePullPolicy":"IfNotPresent","name":"velero-plugin-for-aws","volumeMounts":[{"mountPath":"/target","name":"plugins"}]}],"nodeSelector":{}}` | ----------------------------------------------  This section enables deployment of Velero, a Kubernetes backup and disaster recovery tool.  Key Features: - Backup and restore Kubernetes resources and persistent volumes - Scheduled backups with configurable frequency and retention policies - Support for various backup storage providers (e.g., AWS S3, Azure Blob Storage, etc.) - Plugin system for extending functionality  Key Configuration: - `backupStorage`: Define the storage location for backups (e.g., S3 bucket). - `credentials`: Configure credentials for the backup storage provider (if needed). - `defaultBackupTTL`: Set the default retention period for backups.  Note: Ensure proper configuration of backup storage and credentials for successful operation. |
| zookeeper.enabled | bool | `false` |  |
| zookeeper.fullnameOverride | string | `"zookeeper"` |  |
| zookeeper.nodeSelector | object | `{}` |  |
| zoonavigator | object | `{"affinity":{},"autoscaling":{"enabled":false,"maxReplicas":3,"minReplicas":1,"targetCPUUtilizationPercentage":80,"targetMemoryUtilizationPercentage":80},"enabled":false,"image":{"pullPolicy":"Always","repository":"elkozmon/zoonavigator","tag":"latest"},"imagePullSecrets":[],"nodeSelector":{},"podAnnotations":{},"podSecurityContext":{},"replicaCount":1,"resources":{},"securityContext":{},"service":{"port":80,"type":"ClusterIP"},"tolerations":[]}` | --------------------------  This section enables deployment of Zoo Navigator, a web-based tool for visualizing and managing Apache ZooKeeper clusters.  Key Features: - Single-pod deployment of Zoo Navigator - Configurable Docker image repository, tag, and pull policy - Service definition for exposing Zoo Navigator to the network - Optional settings for pod and container security - Resource limits and requests for CPU and memory - Optional horizontal autoscaling based on CPU/memory utilization - Node selector, tolerations, and affinity controls for pod scheduling  Note: Review and adjust settings according to your ZooKeeper cluster setup and requirements. |

----------------------------------------------

